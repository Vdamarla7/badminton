{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47479338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Add the badminton package to the path\n",
    "sys.path.insert(0, '/work/vdark/badminton')\n",
    "\n",
    "# Define file paths\n",
    "videos_base = \"/work/badminton/VB_DATA/videos/\"\n",
    "poses_base  = \"/work/vdark/badminton/badminton/VB_DATA/poses/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "notebook-header",
   "metadata": {},
   "source": [
    "# OpenAI Badminton Analysis\n",
    "\n",
    "This notebook demonstrates badminton shot analysis using OpenAI's language models.\n",
    "It processes pose data to generate shot descriptions and classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a87239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai\n",
    "\n",
    "from openai import OpenAI\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Import prompt modules\n",
    "import badminton.llm_analysis.bd_prompt as bd_prompt\n",
    "import badminton.llm_analysis.shot_classification_prompt as scp\n",
    "\n",
    "# Import VideoPoseDataset\n",
    "from badminton.data.video_pose_dataset import VideoPoseDataset\n",
    "\n",
    "# Import utility functions\n",
    "from badminton.utilities.coco_keypoints import create_keypoints_dict\n",
    "\n",
    "# Import analysis components\n",
    "from badminton.data.pose_data_loader import PoseDataLoader\n",
    "from badminton.visualization.pose_visualizer import PoseVisualizer\n",
    "from badminton.features.pose_feature_extractor import PoseFeatureExtractor\n",
    "from badminton.analysis.shot_descriptor import ShotDescriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## Annotate Video with Pose Data\n",
    "\n",
    "Load the video and pose data for analysis.\n",
    "Create an annotated video with pose overlays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d004adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Number of frames: 39\n",
      "Video metadata: {'poses_path': '/Users/chanakyd/work/vdark/badminton/badminton/VB_DATA/poses/05_Drop_Shot/2022-09-01_17-49-36_dataset_set1_058_003682_003721_B_05.csv', 'video_path': '/Users/chanakyd/work/badminton/VB_DATA/videos/05_Drop_Shot/2022-09-01_17-49-36_dataset_set1_058_003682_003721_B_05.mp4', 'frame_count': 39, 'fps': 30.0, 'duration': 1.3, 'frame_shape': (720, 1280, 3), 'total_frames': 39}\n"
     ]
    }
   ],
   "source": [
    "video_file = videos_base + \"05_Drop_Shot/2022-09-01_17-49-36_dataset_set1_058_003682_003721_B_05.mp4\"\n",
    "pose_file = poses_base + \"05_Drop_Shot/2022-09-01_17-49-36_dataset_set1_058_003682_003721_B_05.csv\"\n",
    "\n",
    "# Create VideoPoseDataset\n",
    "vpd = VideoPoseDataset(poses_path=pose_file, video_path=video_file)\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Number of frames: {len(vpd)}\")\n",
    "print(f\"Video metadata: {vpd.get_dataset_summary()}\")\n",
    "\n",
    "# Create annotated video\n",
    "vpd.annotate_video_with_poses(\n",
    "    output_path=\"annotated_video.mp4\", \n",
    "    include_bboxes=False, \n",
    "    players=['green', 'blue']\n",
    ")\n",
    "\n",
    "print(\"Annotated video created: annotated_video.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-extraction-section",
   "metadata": {},
   "source": [
    "## Poselets Extraction\n",
    "\n",
    "Poselets provide the orientation of three keypoints relative to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feature-extraction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 39 frames of poselets for green player\n",
      "First frame poselets: {'left_arm': 'P_90_180', 'left_leg': 'P_30_90', 'left_torso': 'P_240_270', 'right_arm': 'P_120_120', 'right_leg': 'P_90_90', 'right_torso': 'P_270_210'}\n",
      "\n",
      "Direct extraction: 39 frames\n",
      "Results match: True\n"
     ]
    }
   ],
   "source": [
    "# Extract poselets\n",
    "poselets_green = vpd.get_poselets_for_player(player='green')\n",
    "poselets_blue = vpd.get_poselets_for_player(player='blue')\n",
    "\n",
    "print(f\"Extracted {len(poselets_green)} frames of poselets for green player\")\n",
    "print(f\"First frame poselets: {poselets_green[0]}\")\n",
    "\n",
    "# Use the feature extractor directly\n",
    "feature_extractor = PoseFeatureExtractor()\n",
    "player_data = vpd.data_loader.get_player_data('green')\n",
    "poselets_direct = feature_extractor.extract_poselets_for_player(player_data)\n",
    "\n",
    "print(f\"\\nDirect extraction: {len(poselets_direct)} frames\")\n",
    "print(f\"Results match: {poselets_green == poselets_direct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shot-description-section",
   "metadata": {},
   "source": [
    "## Shot Description Generation\n",
    "\n",
    "Generate natural language descriptions of the shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "shot-description",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shot description for green player:\n",
      "Position: FrontCourt\n",
      "Frame,left_arm,left_leg,left_torso,right_arm,right_leg,right_torso\n",
      "1,P_90_180,P_30_90,P_240_270,P_120_120,P_90_90,P_270_210\n",
      "2,P_30_270,P_30_90,P_240_240,P_90_150,P_90_90,P_270_210\n",
      "3,P_0_90,P_30_60,P_240_240,P_120_150,P_90_90,P_270_210\n",
      "4,P_30_270,P_30_90,P_240_270,P_90_150,P_90_90,P_270_210\n",
      "5,P_0_90,P_30_90,P_240_270,P_120_150,P_90_90,P_330_210\n",
      "6,P_0_90,P_30_90,P_240_270,P_120_90,P_90_90,P_270_210\n",
      "7,P_60_0,P_30_60,P_240_270,P_120_90,P_90_90,P_210_300\n",
      "8,P_60_0,P_30_60,...\n",
      "\n",
      "Descriptions match: True\n"
     ]
    }
   ],
   "source": [
    "# Generate shot description\n",
    "shot_description = vpd.get_shot_description_for_player(player='green')\n",
    "\n",
    "print(\"Shot description for green player:\")\n",
    "print(shot_description[:500] + \"...\" if len(shot_description) > 500 else shot_description)\n",
    "\n",
    "# Use the shot descriptor directly\n",
    "shot_descriptor = ShotDescriptor()\n",
    "poselets = vpd.get_poselets_for_player('green')\n",
    "description_direct = shot_descriptor.generate_shot_description(poselets, poses_path=pose_file)\n",
    "\n",
    "print(f\"\\nDescriptions match: {shot_description == description_direct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8327f26f",
   "metadata": {},
   "source": [
    "## Prompt Generation\n",
    "\n",
    "Generate the prompt to send to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e1a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate prompt for shot classification\n",
    "prompt = scp.SC_BASE_PROMPT + scp.SC_INPUT_PROMPT + vpd.get_shot_description_for_player(player='green')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "openai-integration-section",
   "metadata": {},
   "source": [
    "## Run inference on OpenAI\n",
    "\n",
    "Use OpenAI's language models for shot classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "openai-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt generated successfully!\n",
      "Prompt length: 8509 characters\n",
      "\n",
      "First 200 characters of prompt:\n",
      "You are a badminton assistant coach trained to recognize badminton shot types from pose sequences.\n",
      "\n",
      "Task:\n",
      "\n",
      "Given: A court position A sequence of pose frames encoded as orientation tokens\n",
      "Output: Predi...\n",
      "OpenAI Response:\n",
      "{\"predictions\": [\n",
      "  {\n",
      "    \"label\": \"05_Drop_Shot\",\n",
      "    \"confidence\": 0.62,\n",
      "    \"evidence\": \"In FrontCourt, the right arm remains mid-range (roughly P_120_120 to P_120_150) with only small elevation changes and the right torso shows minimal rotation; this matches a short, controlled drop shot rather than a smash (which would feature a high cocked right arm and pronounced forward torso rotation) or a serve (not applicable in FrontCourt). Confidence moderate due to lack of clear hallmark of extreme motion but overall fit.\"\n",
      "  }\n",
      "]}\n"
     ]
    }
   ],
   "source": [
    "# OpenAI client setup (add your API key)\n",
    "client = OpenAI(\n",
    "  api_key=\"Enter Your Key Here\"\n",
    ")\n",
    "\n",
    "#model = \"gpt-oss-120b\"\n",
    "model=\"gpt-5-nano\"\n",
    "\n",
    "\n",
    "print(\"Prompt generated successfully!\")\n",
    "print(f\"Prompt length: {len(prompt)} characters\")\n",
    "print(\"\\nFirst 200 characters of prompt:\")\n",
    "print(prompt[:200] + \"...\")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=model,\n",
    "    input=prompt,\n",
    "    store=True)\n",
    " \n",
    "print(\"\")\n",
    "print(\"OpenAI Response:\")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "openai-call",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "badminton-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
